{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33ace866d83d5702",
   "metadata": {},
   "source": "# Tensorflow - Marker Quality Control"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T17:04:00.389861Z",
     "start_time": "2025-09-26T17:03:55.792129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mlflow\n",
    "import tensorflow as tf"
   ],
   "id": "5463cfba48a71e7a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "df2fedb41409ef70",
   "metadata": {},
   "source": "### Définition sure serveur MLFLOW"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T17:04:02.035765Z",
     "start_time": "2025-09-26T17:04:00.393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = tf.saved_model.load(\n",
    "    \"marker_quality_control/1\", tags=None, options=None\n",
    ")"
   ],
   "id": "f193001005b0b3b7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T17:04:02.269996Z",
     "start_time": "2025-09-26T17:04:02.241466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_path = \"images/10.jpg\"\n",
    "img = tf.keras.utils.load_img(img_path, target_size=(224, 224))\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0)\n",
    "img_array = img_array / 255.0"
   ],
   "id": "eb3f847b5f439538",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T17:04:02.275758Z",
     "start_time": "2025-09-26T17:04:02.272915Z"
    }
   },
   "cell_type": "code",
   "source": "img_array",
   "id": "937481e02d6fc749",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 224, 224, 3), dtype=float32, numpy=\n",
       "array([[[[0.3764706 , 0.3372549 , 0.32941177],\n",
       "         [0.3764706 , 0.3372549 , 0.32941177],\n",
       "         [0.38431373, 0.34117648, 0.33333334],\n",
       "         ...,\n",
       "         [0.74509805, 0.70980394, 0.6745098 ],\n",
       "         [0.7490196 , 0.7137255 , 0.6784314 ],\n",
       "         [0.7529412 , 0.7176471 , 0.68235296]],\n",
       "\n",
       "        [[0.4745098 , 0.44313726, 0.43137255],\n",
       "         [0.47058824, 0.4392157 , 0.42745098],\n",
       "         [0.47058824, 0.43137255, 0.42352942],\n",
       "         ...,\n",
       "         [0.7529412 , 0.7176471 , 0.68235296],\n",
       "         [0.7529412 , 0.7176471 , 0.68235296],\n",
       "         [0.7607843 , 0.7254902 , 0.6901961 ]],\n",
       "\n",
       "        [[0.5568628 , 0.5372549 , 0.5254902 ],\n",
       "         [0.5568628 , 0.5372549 , 0.5254902 ],\n",
       "         [0.5647059 , 0.53333336, 0.52156866],\n",
       "         ...,\n",
       "         [0.75686276, 0.72156864, 0.6862745 ],\n",
       "         [0.7607843 , 0.7254902 , 0.6901961 ],\n",
       "         [0.7647059 , 0.7294118 , 0.69411767]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.654902  , 0.654902  , 0.6627451 ],\n",
       "         [0.654902  , 0.654902  , 0.6627451 ],\n",
       "         [0.65882355, 0.65882355, 0.6666667 ],\n",
       "         ...,\n",
       "         [0.7411765 , 0.7019608 , 0.6627451 ],\n",
       "         [0.7411765 , 0.7019608 , 0.6627451 ],\n",
       "         [0.7411765 , 0.7019608 , 0.6627451 ]],\n",
       "\n",
       "        [[0.6392157 , 0.6392157 , 0.64705884],\n",
       "         [0.6431373 , 0.6431373 , 0.6509804 ],\n",
       "         [0.6509804 , 0.6509804 , 0.65882355],\n",
       "         ...,\n",
       "         [0.7372549 , 0.69803923, 0.65882355],\n",
       "         [0.7372549 , 0.69803923, 0.65882355],\n",
       "         [0.7372549 , 0.69803923, 0.65882355]],\n",
       "\n",
       "        [[0.61960787, 0.61960787, 0.627451  ],\n",
       "         [0.627451  , 0.627451  , 0.63529414],\n",
       "         [0.6392157 , 0.6392157 , 0.64705884],\n",
       "         ...,\n",
       "         [0.73333335, 0.69411767, 0.654902  ],\n",
       "         [0.73333335, 0.69411767, 0.654902  ],\n",
       "         [0.7372549 , 0.69803923, 0.65882355]]]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T17:04:02.423057Z",
     "start_time": "2025-09-26T17:04:02.283186Z"
    }
   },
   "cell_type": "code",
   "source": "model(inputs = img_array)",
   "id": "a791b4f865356f9f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[2.3617949e-04, 9.9976379e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "d245f0d70ad85223",
   "metadata": {},
   "source": "### Encapsulation dans un mlflow pyfunc modèle\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T17:04:14.049949Z",
     "start_time": "2025-09-26T17:04:02.447193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://model-platform.com/registry/test/\")\n",
    "mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"custom_model\",\n",
    "            python_model=\"marker_quality_control_wrapper.py\",\n",
    "            artifacts={\"model_path\": \"marker_quality_control/1\"},\n",
    "            registered_model_name=\"marker_quality_control\"\n",
    "        )\n"
   ],
   "id": "9f962f18f428caed",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philippe.stepniewski/Library/Caches/pypoetry/virtualenvs/model-platform-Rq1uDyp9-py3.11/lib/python3.11/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001B[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001B[0m\n",
      "  color_warning(\n",
      "/Users/philippe.stepniewski/Library/Caches/pypoetry/virtualenvs/model-platform-Rq1uDyp9-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 3/3 [00:00<00:00, 1431.34it/s] \n",
      "\u001B[31m2025/09/26 19:04:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n",
      "Successfully registered model 'marker_quality_control'.\n",
      "2025/09/26 19:04:14 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: marker_quality_control, version 1\n",
      "Created version '1' of model 'marker_quality_control'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x35c8c9610>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T17:04:16.911688Z",
     "start_time": "2025-09-26T17:04:14.104919Z"
    }
   },
   "cell_type": "code",
   "source": "model = mlflow.pyfunc.load_model(model_uri=\"models:/marker_quality_control/1\")",
   "id": "731906a1e58db965",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 12.22it/s]   \n",
      "/Users/philippe.stepniewski/Library/Caches/pypoetry/virtualenvs/model-platform-Rq1uDyp9-py3.11/lib/python3.11/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001B[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001B[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T17:04:17.188952Z",
     "start_time": "2025-09-26T17:04:16.920341Z"
    }
   },
   "cell_type": "code",
   "source": "model.predict(img)",
   "id": "774de60a2f1d0c0d",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'JpegImageFile'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/model-platform-Rq1uDyp9-py3.11/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:812\u001B[39m, in \u001B[36mPyFuncModel.predict\u001B[39m\u001B[34m(self, data, params)\u001B[39m\n\u001B[32m    810\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m schema := _get_dependencies_schema_from_model(\u001B[38;5;28mself\u001B[39m._model_meta):\n\u001B[32m    811\u001B[39m     context.update(**schema)\n\u001B[32m--> \u001B[39m\u001B[32m812\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/model-platform-Rq1uDyp9-py3.11/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:862\u001B[39m, in \u001B[36mPyFuncModel._predict\u001B[39m\u001B[34m(self, data, params)\u001B[39m\n\u001B[32m    860\u001B[39m params_arg = inspect.signature(\u001B[38;5;28mself\u001B[39m._predict_fn).parameters.get(\u001B[33m\"\u001B[39m\u001B[33mparams\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    861\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m params_arg \u001B[38;5;129;01mand\u001B[39;00m params_arg.kind != inspect.Parameter.VAR_KEYWORD:\n\u001B[32m--> \u001B[39m\u001B[32m862\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_predict_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    864\u001B[39m _log_warning_if_params_not_in_predict_signature(_logger, params)\n\u001B[32m    865\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._predict_fn(data)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/model-platform-Rq1uDyp9-py3.11/lib/python3.11/site-packages/mlflow/pyfunc/model.py:1175\u001B[39m, in \u001B[36m_PythonModelPyfuncWrapper.predict\u001B[39m\u001B[34m(self, model_input, params)\u001B[39m\n\u001B[32m   1173\u001B[39m     _log_warning_if_params_not_in_predict_signature(_logger, params)\n\u001B[32m   1174\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m _is_context_in_predict_function_signature(parameters=parameters):\n\u001B[32m-> \u001B[39m\u001B[32m1175\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpython_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1176\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_input\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1177\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1178\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1179\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.python_model.predict(\u001B[38;5;28mself\u001B[39m._convert_input(model_input), **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/model-platform-Rq1uDyp9-py3.11/lib/python3.11/site-packages/mlflow/pyfunc/utils/data_validation.py:77\u001B[39m, in \u001B[36m_wrap_predict_with_pyfunc.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     75\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[32m     76\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapper\u001B[39m(*args, **kwargs):\n\u001B[32m---> \u001B[39m\u001B[32m77\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/var/folders/k0/jqyr0y117r5gkrs84q5rb43c0000gn/T/tmprh_q7i93/marker_quality_control_wrapper.py:15\u001B[39m, in \u001B[36mMarkerQualityControlWrapper.predict\u001B[39m\u001B[34m(self, context, model_input)\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, context, model_input):\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m     image = Image.open(\u001B[43mio\u001B[49m\u001B[43m.\u001B[49m\u001B[43mBytesIO\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_input\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     16\u001B[39m     img_array = np.array(image)\n\u001B[32m     17\u001B[39m     img = tf.convert_to_tensor(img_array, dtype=tf.float32)\n",
      "\u001B[31mTypeError\u001B[39m: a bytes-like object is required, not 'JpegImageFile'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "11d6135b9bf8f6d0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
